{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KSwUDsfsZxXB"
   },
   "source": [
    "# Seq2Seq_code\n",
    "\n",
    "ps：\n",
    "\n",
    "pip install d2l\n",
    "\n",
    "pip install matplotlib==3.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "puCueUPjZyE2"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from d2l import torch as d2l\n",
    "from model import RNN\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import matplotlib.pyplot as plt\n",
    "import collections\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ejR2ddP-kEkq"
   },
   "source": [
    "## Trasnlation Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X9vx_pJekEL5",
    "outputId": "45909eab-0953-4cc3-eec5-cd155661c0df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go.\tVa !\n",
      "Hi.\tSalut !\n",
      "Run!\tCours !\n",
      "Run!\tCourez !\n",
      "Who?\tQui ?\n",
      "Wow!\tÇa alors !\n",
      "\n"
     ]
    }
   ],
   "source": [
    "d2l.DATA_HUB['fra-eng'] = (d2l.DATA_URL + 'fra-eng.zip',\n",
    "  '94646ad1522d915e7b0f9296181140edcf86a4f5')\n",
    "\n",
    "def read_data_nmt():\n",
    "  \"\"\"载⼊“英语－法语”数据集\"\"\"\n",
    "  data_dir = d2l.download_extract('fra-eng')\n",
    "  with open(os.path.join(data_dir, 'fra.txt'), 'r',\n",
    "  encoding='utf-8') as f:\n",
    "    return f.read()\n",
    "raw_text = read_data_nmt()\n",
    "print(raw_text[:75])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OOk7QcfjT2dt",
    "outputId": "d6b83541-6718-4ed0-bb3c-c4d2ab0752cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "go .\tva !\n",
      "hi .\tsalut !\n",
      "run !\tcours !\n",
      "run !\tcourez !\n",
      "who ?\tqui ?\n",
      "wow !\tça alors !\n"
     ]
    }
   ],
   "source": [
    "def preprocess_nmt(text):\n",
    "  \"\"\"预处理“英语－法语”数据集\"\"\"\n",
    "  def no_space(char, prev_char):\n",
    "    return char in set(',.!?') and prev_char != ' '\n",
    "\n",
    "  # 使⽤空格替换不间断空格\n",
    "  # 使⽤⼩写字⺟替换⼤写字⺟\n",
    "  text = text.replace('\\u202f', ' ').replace('\\xa0', ' ').lower()\n",
    "  # 在单词和标点符号之间插⼊空格\n",
    "  out = [' ' + char if i > 0 and no_space(char, text[i - 1]) else char\n",
    "      for i, char in enumerate(text)]\n",
    "  return ''.join(out)\n",
    "  \n",
    "text = preprocess_nmt(raw_text)\n",
    "print(text[:80])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wnMGk7JmUAIF",
    "outputId": "a1d3b608-a1cd-4e48-8e45-234831b30967"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([['go', '.'],\n",
       "  ['hi', '.'],\n",
       "  ['run', '!'],\n",
       "  ['run', '!'],\n",
       "  ['who', '?'],\n",
       "  ['wow', '!']],\n",
       " [['va', '!'],\n",
       "  ['salut', '!'],\n",
       "  ['cours', '!'],\n",
       "  ['courez', '!'],\n",
       "  ['qui', '?'],\n",
       "  ['ça', 'alors', '!']])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize_nmt(text, num_examples=None):\n",
    "  \"\"\"词元化“英语－法语”数据数据集\"\"\"\n",
    "  source, target = [], []\n",
    "  for i, line in enumerate(text.split('\\n')):\n",
    "    if num_examples and i > num_examples:\n",
    "      break\n",
    "    parts = line.split('\\t')\n",
    "    if len(parts) == 2:\n",
    "      source.append(parts[0].split(' '))\n",
    "      target.append(parts[1].split(' '))\n",
    "  return source, target\n",
    "  \n",
    "source, target = tokenize_nmt(text)\n",
    "source[:6], target[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NmbsoltcU9pe",
    "outputId": "4a2b6168-6d1f-4248-d2b1-5f868b463d3b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10012"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_vocab = RNN.Vocab(source, min_freq=2, reserved_tokens=['<pad>', '<bos>', '<eos>'])\n",
    "len(src_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "20bynABcVLje",
    "outputId": "36bc51aa-9fc9-49ab-b09d-3dd0f1a09fa4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[47, 4, 1, 1, 1, 1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def truncate_pad(line, num_steps, padding_token):\n",
    "  \"\"\"截断或填充⽂本序列\"\"\"\n",
    "  if len(line) > num_steps:\n",
    "    return line[:num_steps] # 截断\n",
    "  return line + [padding_token] * (num_steps - len(line)) # 填充\n",
    "truncate_pad(src_vocab[source[0]], 10, src_vocab['<pad>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Pasvc0xtdnDm"
   },
   "outputs": [],
   "source": [
    "def build_array_nmt(lines, vocab, num_steps):\n",
    "  \"\"\"将机器翻译的⽂本序列转换成⼩批量\"\"\"\n",
    "  lines = [vocab[l] for l in lines]\n",
    "  lines = [l + [vocab['<eos>']] for l in lines]\n",
    "  array = torch.tensor([truncate_pad(\n",
    "      l, num_steps, vocab['<pad>']) for l in lines])\n",
    "  valid_len = (array != vocab['<pad>']).type(torch.int32).sum(1)\n",
    "  return array, valid_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "KqdngZftzmaP"
   },
   "outputs": [],
   "source": [
    "def load_data_nmt(batch_size, num_steps, num_examples=600):\n",
    "  \"\"\"返回翻译数据集的迭代器和词表\"\"\"\n",
    "  text = preprocess_nmt(read_data_nmt())\n",
    "  source, target = tokenize_nmt(text, num_examples)\n",
    "  src_vocab = RNN.Vocab(source, min_freq=2,\n",
    "            reserved_tokens=['<pad>', '<bos>', '<eos>'])\n",
    "  tgt_vocab = d2l.Vocab(target, min_freq=2,\n",
    "            reserved_tokens=['<pad>', '<bos>', '<eos>'])\n",
    "  src_array, src_valid_len = build_array_nmt(source, src_vocab, num_steps)\n",
    "  tgt_array, tgt_valid_len = build_array_nmt(target, tgt_vocab, num_steps)\n",
    "  data_arrays = (src_array, src_valid_len, tgt_array, tgt_valid_len)\n",
    "  data_iter = DataLoader(dataset=TensorDataset(*data_arrays), \n",
    "                 batch_size=batch_size, shuffle=True)\n",
    "  return data_iter, src_vocab, tgt_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GNXoQLcx2-gb",
    "outputId": "6a2bc1bb-54b9-44f8-a99d-9dafb117e081"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: tensor([[ 71,   5,   3,   1,   1,   1,   1,   1],\n",
      "        [109,  10,   4,   3,   1,   1,   1,   1]], dtype=torch.int32)\n",
      "X的有效⻓度: tensor([3, 4])\n",
      "Y: tensor([[15,  0, 98,  5,  3,  1,  1,  1],\n",
      "        [92,  8,  4,  3,  1,  1,  1,  1]], dtype=torch.int32)\n",
      "Y的有效⻓度: tensor([5, 4])\n"
     ]
    }
   ],
   "source": [
    "train_iter, src_vocab, tgt_vocab = load_data_nmt(batch_size=2, num_steps=8)\n",
    "for X, X_valid_len, Y, Y_valid_len in train_iter:\n",
    "  print('X:', X.type(torch.int32))\n",
    "  print('X的有效⻓度:', X_valid_len)\n",
    "  print('Y:', Y.type(torch.int32))\n",
    "  print('Y的有效⻓度:', Y_valid_len)\n",
    "  break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0vDD3liL3kr7"
   },
   "source": [
    "## Seq2Seq\n",
    "\n",
    "序列到序列学习——以机器翻译为例\n",
    "\n",
    "机器翻译中的输入序列和输出序列都是⻓度可变的。为了解决这类问题，我们将使用两个循环神经网络的编码器和解 码器，并将其应用于序列到序列(sequence to sequence，seq2seq)类的学习任务.\n",
    "\n",
    "![title](attachment/seq2seq.png)\n",
    "\n",
    "特定的“\\<eos>”表示序列结束词元。一旦输出序列生成此词元，模型就会停止预测。在循环神\n",
    "经网络解码器的初始化时间步，有两个特定的设计决定:首先，特定的“\\<bos>”表示序列开始词元，它是解码器的输入序列的第一个词元。其次，使用循环神经网络编码器最终的隐状态来初始化解码器的隐状态。\n",
    "\n",
    "根据Encoder-Decoder来设计网络\n",
    "![title](attachment/seq2seq2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fCGRouf3_tjU"
   },
   "source": [
    "- Seq2Seq Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "pMSB6wIU2-Yz"
   },
   "outputs": [],
   "source": [
    "class Seq2SeqEncoder(nn.Module):\n",
    "  def __init__(self, vocab_size, embed_size, num_hiddens, num_layers,\n",
    "               dropout=0, **kwargs):\n",
    "    super().__init__(**kwargs)\n",
    "    # embedding\n",
    "    self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "    self.rnn = nn.GRU(embed_size, num_hiddens, num_layers, dropout=dropout)\n",
    "\n",
    "  def forward(self, X, *args):\n",
    "    # 输出'X'的形状：(batch_size,num_steps,embed_size)\n",
    "    X = self.embedding(X)\n",
    "    X = X.permute(1, 0, 2)\n",
    "    output, state = self.rnn(X)\n",
    "    return output, state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7tTmHLIR_Ga2",
    "outputId": "f0355891-e6f2-4574-eee3-dfeb9d2f4617"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([7, 4, 16]), torch.Size([2, 4, 16]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = Seq2SeqEncoder(vocab_size=10, embed_size=8, num_hiddens=16,\n",
    "                num_layers=2)\n",
    "encoder.eval()\n",
    "X = torch.zeros((4, 7), dtype=torch.long)\n",
    "output, state = encoder(X)\n",
    "output.shape, state.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7XZ9WiL-_xI8"
   },
   "source": [
    "- Seq2Seq Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "oevtkXSi_kUn"
   },
   "outputs": [],
   "source": [
    "class Seq2SeqDecoder(nn.Module):\n",
    "  \"\"\"⽤于序列到序列学习的循环神经⽹络解码器\"\"\"\n",
    "  def __init__(self, vocab_size, embed_size, num_hiddens, num_layers,\n",
    "          dropout=0, **kwargs):\n",
    "    super().__init__(**kwargs)\n",
    "    self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "    self.rnn = nn.GRU(embed_size + num_hiddens, num_hiddens, num_layers,\n",
    "                dropout=dropout)\n",
    "    self.dense = nn.Linear(num_hiddens, vocab_size)\n",
    "\n",
    "  def init_state(self, enc_outputs, *args):\n",
    "    return enc_outputs[1]\n",
    "\n",
    "  def forward(self, X, state):\n",
    "    X = self.embedding(X).permute(1, 0, 2)\n",
    "    context = state[-1].repeat(X.shape[0], 1, 1)\n",
    "    X_and_context = torch.cat((X, context), 2)\n",
    "    # return X, context\n",
    "    output, state = self.rnn(X_and_context, state)\n",
    "    output = self.dense(output).permute(1, 0, 2)\n",
    "    return output, state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hkClNry6DCkI",
    "outputId": "af37c0da-30f2-4231-9d71-bf2d6f8332ae"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 7, 10]), torch.Size([2, 4, 16]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder = Seq2SeqDecoder(vocab_size=10, embed_size=8, num_hiddens=16,\n",
    "      num_layers=2)\n",
    "decoder.eval()\n",
    "state = decoder.init_state(encoder(X))\n",
    "output, state = decoder(X, state)\n",
    "output.shape, state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "pxlmabKAVJTj"
   },
   "outputs": [],
   "source": [
    "class EncoderDecoder(nn.Module):\n",
    "  \"\"\"编码器-解码器架构的基类\"\"\"\n",
    "  def __init__(self, encoder, decoder, **kwargs):\n",
    "    super().__init__(**kwargs)\n",
    "    self.encoder = encoder\n",
    "    self.decoder = decoder\n",
    "\n",
    "  def forward(self, enc_X, dec_X, *args):\n",
    "    enc_outputs = self.encoder(enc_X, *args)\n",
    "    dec_state = self.decoder.init_state(enc_outputs, *args)\n",
    "    return self.decoder(dec_X, dec_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OxqllknLHSC2"
   },
   "source": [
    "- loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "J8emcWTOHTEw"
   },
   "outputs": [],
   "source": [
    "def sequence_mask(X, valid_len, value=0):\n",
    "  \"\"\"在序列中屏蔽不相关的项\"\"\"\n",
    "  maxlen = X.size(1)\n",
    "  mask = torch.arange((maxlen), dtype=torch.float32,\n",
    "          device=X.device)[None, :] < valid_len[:, None]\n",
    "  X[~mask] = value\n",
    "  return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wpUAzReOHzk-",
    "outputId": "ddbc4f14-68b2-46e0-c5b5-85763d8ed283"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 0],\n",
       "        [4, 5, 0]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "sequence_mask(X, torch.tensor([1, 2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SCZpE1uaIXid",
    "outputId": "e7a79283-a710-467f-a351-24355977df3e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.3026, 1.1513, 0.0000])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MaskedSoftmaxCELoss(nn.CrossEntropyLoss):\n",
    "  \"\"\"带遮蔽的softmax交叉熵损失函数\"\"\"\n",
    "  # pred的形状：(batch_size,num_steps,vocab_size)\n",
    "  # label的形状：(batch_size,num_steps)\n",
    "  # valid_len的形状：(batch_size,)\n",
    "  def forward(self, pred, label, valid_len):\n",
    "    weights = torch.ones_like(label)\n",
    "    weights = sequence_mask(weights, valid_len)\n",
    "    self.reduction='none'\n",
    "    unweighted_loss = super().forward(\n",
    "                pred.permute(0, 2, 1), label)\n",
    "    weighted_loss = (unweighted_loss * weights).mean(dim=1)\n",
    "    return weighted_loss\n",
    "\n",
    "loss = MaskedSoftmaxCELoss()\n",
    "loss(torch.ones(3, 4, 10), torch.ones((3, 4), dtype=torch.long),\n",
    "        torch.tensor([4, 2, 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZF6SRqL-Rqol"
   },
   "source": [
    "- Train\n",
    "\n",
    "特定的序列开始词元(“<bos>”)和原始的输出序列(不包括序 列结束词元“<eos>”)拼接在一起作为解码器的输入。这被称为强制教学(teacher forcing)，因为原始的输 出序列(词元的标签)被送入解码器。或者，将来自上一个时间步的预测得到的词元作为解码器的当前输入。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4UoS-c9UQ37G",
    "outputId": "f82829a1-3268-4296-e3a3-be34694b80dd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(184, 201)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1.载入数据集\n",
    "embed_size, num_hiddens, num_layers, dropout = 32, 32, 2, 0.1\n",
    "batch_size, num_steps = 64, 10\n",
    "train_iter, src_vocab, tgt_vocab = load_data_nmt(batch_size, num_steps)\n",
    "len(src_vocab), len(tgt_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "Q4m4QskcR570"
   },
   "outputs": [],
   "source": [
    "# 2.定义网络\n",
    "encoder = Seq2SeqEncoder(len(src_vocab), embed_size, num_hiddens, num_layers,\n",
    "                dropout)\n",
    "decoder = Seq2SeqDecoder(len(tgt_vocab), embed_size, num_hiddens, num_layers,\n",
    "                dropout)\n",
    "net = EncoderDecoder(encoder, decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "LYmjJFL7VaDB"
   },
   "outputs": [],
   "source": [
    "# 3.初始化weight\n",
    "def xavier_init_weights(m):\n",
    "  if type(m) == nn.Linear:\n",
    "    nn.init.xavier_uniform_(m.weight)\n",
    "  if type(m) == nn.GRU:\n",
    "    for param in m._flat_weights_names:\n",
    "      if \"weight\" in param:\n",
    "        nn.init.xavier_uniform_(m._parameters[param])\n",
    "\n",
    "net.apply(xavier_init_weights)\n",
    "\n",
    "# 4.定义losss和optimizer\n",
    "loss = MaskedSoftmaxCELoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "C7Fv83Oug9c4"
   },
   "outputs": [],
   "source": [
    "# Train\n",
    "def train_seq2seq(net, epochs, train_iter, loss, optim, tgt_vocab,\n",
    "  grad_clip_theta=1, device=torch.device('cuda')):\n",
    "  net.to(device)\n",
    "  net.train()\n",
    "\n",
    "  loss_fig = []\n",
    "  for epoch in range(epochs):\n",
    "    epoch_loss = []\n",
    "    for batch in train_iter:\n",
    "      optim.zero_grad()\n",
    "      X, X_valid_len, Y, Y_valid_len = [x.to(device) for x in batch]\n",
    "      bos = torch.tensor([tgt_vocab['<bos>']] * Y.shape[0],\n",
    "                          device=device).reshape(-1, 1)\n",
    "      dec_input = torch.cat([bos, Y[:, :-1]], 1) # 强制教学\n",
    "      Y_hat, _ = net(X, dec_input, X_valid_len)\n",
    "      l = loss(Y_hat, Y, Y_valid_len)\n",
    "      epoch_loss.append(l.mean().item())\n",
    "      l.sum().backward()\n",
    "      RNN.grad_clipping(net, grad_clip_theta)\n",
    "      optimizer.step()\n",
    "    epoch_perplexity = np.mean(epoch_loss)\n",
    "    if (epoch+1)%50==0:\n",
    "        print(f'epoch: {epoch+1}, loss:{epoch_perplexity:f}')\n",
    "    loss_fig.append(epoch_perplexity)\n",
    "\n",
    "  plt.plot(loss_fig, label='train', color='b', linestyle='solid')\n",
    "  plt.xlabel('epoch')\n",
    "  plt.ylabel('loss')\n",
    "  plt.legend()\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 467
    },
    "id": "ayRbOfqQjmi9",
    "outputId": "82bcb9a2-e8ae-44c0-95c3-ec3e2dc632d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 50, loss:0.359615\n",
      "epoch: 100, loss:0.356440\n",
      "epoch: 150, loss:0.361306\n",
      "epoch: 200, loss:0.372953\n",
      "epoch: 250, loss:0.333217\n",
      "epoch: 300, loss:0.339131\n",
      "epoch: 350, loss:0.340814\n",
      "epoch: 400, loss:0.316321\n",
      "epoch: 450, loss:0.322320\n",
      "epoch: 500, loss:0.304380\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_seq2seq(net, 500, train_iter, loss, optimizer, tgt_vocab,\n",
    "        grad_clip_theta=1, device=torch.device('cuda'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- predict\n",
    "\n",
    "为了采用一个接着一个词元的方式预测输出序列，每个解码器当前时间步的输入都将来自于前一时间步的预 测词元。与训练类似，序列开始词元(“\\<bos>”)在初始时间步被输入到解码器中,当输出序列的预测遇到序列结束词元(“<eos>”)时，预测就结束了。\n",
    "![title](attachment/seq2seq.png)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_seq2seq(net, src_sentence, src_vocab, tgt_vocab, num_steps,\n",
    "                    device=torch.device('cuda'), save_attention_weights=False):\n",
    "    net.eval()\n",
    "    src_tokens = src_vocab[src_sentence.lower().split(' ')] + [\n",
    "                            src_vocab['<eos>']]\n",
    "    enc_valid_len = torch.tensor([len(src_tokens)], device=device)\n",
    "    src_tokens = truncate_pad(src_tokens, num_steps, src_vocab['<pad>'])\n",
    "    enc_X = torch.unsqueeze(\n",
    "        torch.tensor(src_tokens, dtype=torch.long, device=device), dim=0)\n",
    "    enc_outputs = net.encoder(enc_X, enc_valid_len)\n",
    "    dec_state = net.decoder.init_state(enc_outputs, enc_valid_len)\n",
    "    dec_X = torch.unsqueeze(torch.tensor(\n",
    "                [tgt_vocab['<bos>']], dtype=torch.long, device=device), dim=0)\n",
    "    output_seq, attention_weight_seq = [], []\n",
    "    for _ in range(num_steps):\n",
    "        Y, dec_state = net.decoder(dec_X, dec_state)\n",
    "        # 我们使⽤具有预测最⾼可能性的词元，作为解码器在下⼀时间步的输⼊\n",
    "        dec_X = Y.argmax(dim=2)\n",
    "        pred = dec_X.squeeze(dim=0).type(torch.int32).item()\n",
    "        if save_attention_weights:\n",
    "            attention_weight_seq.append(net.decoder.attention_weights)\n",
    "        # ⼀旦序列结束词元被预测，输出序列的⽣成就完成了\n",
    "        if pred == tgt_vocab['<eos>']:\n",
    "            break\n",
    "        output_seq.append(pred)\n",
    "    return ' '.join(tgt_vocab.to_tokens(output_seq)), attention_weight_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('il est <unk> .', [])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_seq2seq(net, 'he\\'s clam', src_vocab, tgt_vocab, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Eval\n",
    "\n",
    "BLEU（bilingual evaluation understudy）\n",
    "\n",
    "我们可以通过与真实的标签序列进行比较来评估预测序列。虽然 [Papineni et al., 2002] 提出的BLEU (bilingual evaluation understudy)最先是用于评估机器翻译的结果，但现在它已经被广泛用于测量许多应用的输出序列的质量。\n",
    "\n",
    "原则上说，对于预测序列中的任意n元语法(n-grams)，BLEU的评估都是这个n元\n",
    "语法是否出现在标签序列中。\n",
    "\n",
    "$$\n",
    "BELU = exp(min(0, 1-\\frac{len_{label}}{len_{predict}}))\\prod_{n=1}^kp_n^{\\frac{1}{2^n}}\n",
    "$$\n",
    "\n",
    "其中lenlabel表示标签序列中的词元数和 lenpred表示预测序列中的词元数，k是用于匹配的最⻓的n元语法。\n",
    "\n",
    "另外，用pn 表示n元语法的精确度，它是两个数量的比值:第一个是预测序列与标签序列中匹配的n元语法的数 量，第二个是预测序列中n元语法的数量的比率。\n",
    "\n",
    "当预测序列与标签序列完全相同时，BLEU为1, 由于n元语法越⻓则匹配难度越大，所以BLEU为更⻓的n元语法的精确度分配更大的权重。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bleu(pred_seq, label_seq, k): #@save\n",
    "    \"\"\"计算BLEU\"\"\"\n",
    "    pred_tokens, label_tokens = pred_seq.split(' '), label_seq.split(' ')\n",
    "    len_pred, len_label = len(pred_tokens), len(label_tokens)\n",
    "    score = math.exp(min(0, 1 - len_label / len_pred))\n",
    "    for n in range(1, k + 1):\n",
    "        num_matches, label_subs = 0, collections.defaultdict(int)\n",
    "        for i in range(len_label - n + 1):\n",
    "            label_subs[' '.join(label_tokens[i: i + n])] += 1\n",
    "        for i in range(len_pred - n + 1):\n",
    "            if label_subs[' '.join(pred_tokens[i: i + n])] > 0:\n",
    "                num_matches += 1\n",
    "                label_subs[' '.join(pred_tokens[i: i + n])] -= 1\n",
    "        score *= math.pow(num_matches / (len_pred - n + 1), math.pow(0.5, n))\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6580370064762462"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = predict_seq2seq(net, 'he\\'s calm .', src_vocab, tgt_vocab, 10)\n",
    "bleu(t[0], 'il est calme .', k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "go . => pred: va doucement ! => true: va !, bleu 0.000\n",
      "i lost . => pred: je l'ai vu . => true: j'ai perdu ., bleu 0.000\n",
      "he's calm . => pred: il est paresseux . => true: il est calme ., bleu 0.658\n",
      "i'm home . => pred: je suis <unk> . => true: je suis chez moi ., bleu 0.512\n"
     ]
    }
   ],
   "source": [
    "engs = ['go .', \"i lost .\", 'he\\'s calm .', 'i\\'m home .']\n",
    "fras = ['va !', 'j\\'ai perdu .', 'il est calme .', 'je suis chez moi .']\n",
    "for eng, fra in zip(engs, fras):\n",
    "    translation, attention_weight_seq = predict_seq2seq(\n",
    "            net, eng, src_vocab, tgt_vocab, num_steps)\n",
    "    print(f'{eng} => pred: {translation} => true: {fra}, bleu {bleu(translation, fra, k=2):.3f}')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Net.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
